---
comments: true
---

# 핵심 알고리즘 - yolov4

CNN(convolutional Neural Network)과 DNN(Deep Neural Network)을 합쳐서 사용. 

이때 객체 인지를 위한 1) region proposal 2) classification 두 단계를 거쳐야 하는데 

이것을 neural network에 포함시켜서 한번에 객체 탐지를 수행하는 구조인 ‘YOLO’ 사용(YOLO의 예측 결과는 클래스 별로 예측된 bounding box)

---
---
글 읽는 순서
1. github repository의 readme 파일- 파일 구성과 핵심 개요 https://github.com/BaekJongSeong/contest/blob/master/README.md
2. github.io의 해커톤- yolov4 알고리즘에 대한 설명 https://baekjongseong.github.io/
3. github.io의 해커톤2- 해커톤 전반적인 과정,특징 세부 설명 https://baekjongseong.github.io/

---
---

+ tensorflow의 keras 프레임워크를 적용하여 CNN(convolutional Neural Network)과 Yolo layer를 이용.
+ CNN을 위한 filter 처리를 진행
+ Filter를 input data에 적용하여 feature map 생성.
+ Filter 값은 input data의 특징을 학습하는 가중치 행렬.
+ 동일한 filter로 input data 전체에 합성 곱 연산(convolutional)
+ 먼저 CNN을 거친 후 Yolo layer를 거침. 
+ 연산을 줄이기 위해서 가중치 수를 줄이며 filter로 feature map을 형성하는 convolutional 과정(filter를 거친 출력값이 feature map)을 여러 번 거침. 
+ 이때 중간마다 max-pooling이라는 과정을 거치는데 이것은 가로 및 세로로 크기를 줄이는 연산으로 max 값을 사용.
+ 그 후 yolo layer 진행


![image](https://user-images.githubusercontent.com/79182947/109409279-d942e680-79d4-11eb-977a-4ed8cf6ba292.png)

---
하나의 convolutional network 가 동시에 여러개의 bounding boxes를 예측하고, 각 bounding box에 대해 class probabilities 를 예측(앞의 사진처럼 반복되는 conv2d를 지날때마다 예측 + 그 box의 예측 대한 confidence score를 같이 예측_ confidence score은 얼마나 박스 안에 실제로 object가 존재하는지)

![image](https://user-images.githubusercontent.com/79182947/109409291-f5468800-79d4-11eb-848c-d6c0e13e0ff2.png)


+ 각 Bounding box는 5가지 예측을 한다.  x, y, w, h, confidence
+ (x,y)는 grid cell의 영역에 관련된 box의 center를 의미한다. confidence는 ground truth box와 예측된 box의 IOU를 예측한다.

+ 시스템은 input image를 S x S grid로 나눔
+ 각 grid cell은 B개의 bounding boxes를 예측 
+ 그 box에 대한 confidence score를 같이 예측.
Ex) 콘테스트에서 class = 3이니까 bounding box가 한 cell마다 2개씩 그려진다고 하면 각 bounding box마다 class 3개에 대한 예측 값 +각각마다 5개의 요소를 가짐(x y w h confidence) . 
그러므로 grid를 7*7로 잡으면 7*7(3+2*5)가 최종 출력

---
+ 7*7grid의 경우,7*7*B개의 bounding box들이 나올 텐데 이때 중복 값들을 아래의 방법을 통해서 제거.
  + 1. Thresholding by Object Confidence Score
    + 말 그대로 object box에서 confidence를 threshold아래로 예측한 box는 무시하는 방법 
    + 이때 이 경계박스들은 threshold ex)0.25보다 작으면 지워준다
    
  + 2. Non-maximum Suppression
    + 한 object를 판단했다고 여겨지는 중복되는 것들은 제거하는 방법. 
    + 경계 박스 안쪽에 어떤 object가 있을 것 같다고 확신하는 confidence score가 높을 수록 박스를 굵게 그려줘서 최종 박스만 남김. 나머지는 지움

+ confidence score = pr(object) * IOU
  + pr(object)는 bounding box 안에 물체가 존재할 확률
  + IOU는 학습데이터의 bounding box와 예측한 bounding box가 일치하는 정도
  + 클래스 확률 C: 그리드 셀 안에 있는 그림의 분류 확률 = Pr(Class_i | object)
  + 그래서 최종 C와 각 바운딩 박스의 confidence 값을 곱하면 각 박스의 클래스별 confidence score 도출

맨 마지막의 training network는 앞의 feature들을 이용하여 class probability와 bounding box를 학습하고 예측하는 네트워크

그러므로 Yolo layer는 S*S(5*B+C)개의 파라미터를 결과로 출력



![2021-02-28](https://user-images.githubusercontent.com/79182947/109408567-40a96800-79ce-11eb-97bb-a8878e8cd3ab.png)
![image](https://user-images.githubusercontent.com/79182947/109408598-63d41780-79ce-11eb-84b8-33b7d41a5a38.png)
![image](https://user-images.githubusercontent.com/79182947/109408609-79494180-79ce-11eb-8fa0-a70115938552.png)
![image](https://user-images.githubusercontent.com/79182947/109408624-92ea8900-79ce-11eb-90b2-3ee1bea971b2.png)



